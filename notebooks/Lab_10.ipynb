{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mrSe1C2eQIzR"
   },
   "source": [
    "# Implementing a DCGAN: Image Generation with Deep Convolutional GANs\n",
    "\n",
    "In this lab, you will construct a Deep Convolutional Generative Adversarial Network (DCGAN). Key concepts covered include:\n",
    "\n",
    "* **Convolutional Architectures for Image Generation:** Discover why convolutional layers excel at image-related tasks.\n",
    "* **Generative Adversarial Networks (GANs):**  Understand the adversarial training process between the generator and discriminator networks.\n",
    "\n",
    "Let's proceed with implementing your DCGAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a30CAGsXQkAy"
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "**Dataset:**   We'll use a grayscale dataset (Fashion-MNIST) for this exercise. To speed up computation (these networks can be quite computationally intensive), we'll resize the images to 16x16 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ANjuxKp9OZv_"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Load and Prepare Fashion-MNIST Dataset\n",
    "(train_images, train_labels), (_, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Resize Images\n",
    "resized_images = resize(train_images, (train_images.shape[0], 16, 16, 1),\n",
    "                        preserve_range=True).astype(\"float32\")\n",
    "\n",
    "# Normalize Pixel Values\n",
    "normalized_images = (resized_images - 127.5) / 127.5\n",
    "\n",
    "# Verify Shape  \n",
    "print(normalized_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UfDcsM5nOZwY"
   },
   "outputs": [],
   "source": [
    "data_generator = tf.data.Dataset.from_tensor_slices(\n",
    "    normalized_images).shuffle(60000).batch(100, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tROMZuCMOZwi"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_images(images, rows=2, cols=10, figsize=(20, 3)):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    for i in range(rows * cols):\n",
    "        ax = plt.subplot(rows, cols, i + 1)\n",
    "        ax.set_axis_off()\n",
    "        ax.imshow(images[i, :, :, 0], cmap='gray')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "colab_type": "code",
    "id": "znZpg2RWOZws",
    "outputId": "533fc1f6-46e2-465b-da89-082c3fafa755"
   },
   "outputs": [],
   "source": [
    "display_images(normalized_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MH0F6r-gRAKN"
   },
   "source": [
    "## Architecting the Generator and Discriminator\n",
    "\n",
    "Let's design the core components of the DCGAN.\n",
    "\n",
    "### Generator: Crafting Images from Noise\n",
    "\n",
    "The generator transforms random noise into realistic images. This network typically consists of:\n",
    "\n",
    "* **Input:**  Random noise (e.g., 100 dimensions).\n",
    "* **Series of Transposed Convolutional Layers:** Upsample the noise into a tensor that resembles an image.  A typical structure might be:\n",
    "    1. 512 channels, kernel size 4, stride 1, 'valid' padding, BatchNorm, LeakyReLU\n",
    "    2. 256 channels, kernel size 4, stride 2, 'same' padding, BatchNorm, LeakyReLU\n",
    "    3. 128 channels, kernel size 4, stride 1, 'same' padding, BatchNorm, LeakyReLU\n",
    "* **Output:**  A 16x16x1 image.\n",
    "\n",
    "### Understanding Transposed Convolutions\n",
    "\n",
    "The transposed convolution (also known as a deconvolution) is the key to the generator's ability to upsample the noise into an image.  It is the opposite of a standard convolution.  Given an input, it will increase the dimensions by padding the input with zeros and then applying a convolution.  This is why it is sometimes called an \"upsampling\" layer.\n",
    "\n",
    "### Batch Normalization\n",
    "\n",
    "Batch normalization is a technique to improve the training of deep neural networks.  It works by normalizing the input of each layer, meaning that the input to each layer has a mean of zero and a standard deviation of one.  This helps to stabilize and speed up training.\n",
    "\n",
    "### LeakyReLU\n",
    "\n",
    "LeakyReLU is a variant of the ReLU activation function.  It has a small slope for negative values, which can help to prevent the \"dying ReLU\" problem. This problem occurs when a ReLU neuron always outputs the same value (e.g., 0), effectively \"dying\" and ceasing to learn.\n",
    "\n",
    "### Discriminator: Discerning Real from Fake\n",
    "\n",
    "The discriminator learns to distinguish between real images and the generator's creations.   A typical structure might be:\n",
    "\n",
    "* **Input:**  Image data.\n",
    "* **Series of Convolutions:** Extract features, as we are familiar with from image classification tasks.  A typical structure might be:\n",
    "    1. 128 channels, kernel size 4, stride 2, 'same' padding, BatchNorm, LeakyReLU\n",
    "    1. 256 channels, kernel size 4, stride 2, 'same' padding, BatchNorm, LeakyReLU\n",
    "\n",
    "* **Output:** A single value indicating whether the input image is real or fake.\n",
    "\n",
    "Let's start implementing these networks in code! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x5266izYAhRN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import BatchNormalization, Flatten, Input\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def get_generator():\n",
    "    input_noise = Input(shape=(1, 1, 100))\n",
    "\n",
    "    # ====== Block 1 ======\n",
    "    x = Conv2DTranspose(512, kernel_size=4, strides=1, padding=\"valid\")(input_noise)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    # =====================\n",
    "\n",
    "    # ====== Block 2 ======\n",
    "    # TODO\n",
    "    # =====================\n",
    "\n",
    "    # ====== Block 3 ======\n",
    "    # TODO\n",
    "    # =====================\n",
    "\n",
    "    x = Conv2DTranspose(1, kernel_size=4, strides=2, padding=\"same\", activation=\"tanh\")(x)\n",
    "\n",
    "    return Model(inputs=input_noise, outputs=x)\n",
    "\n",
    "\n",
    "def get_discriminator():\n",
    "    input_image = Input(shape=(16, 16, 1))\n",
    "\n",
    "    # ====== Block 1 ======\n",
    "    x = Conv2D(128, kernel_size=4, strides=2, padding=\"same\")(input_image)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    # =====================\n",
    "\n",
    "    # ====== Block 2 ======\n",
    "    # TODO\n",
    "    # =====================\n",
    "\n",
    "    x = Conv2D(1, kernel_size=4, strides=1, padding=\"valid\")(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    return Model(inputs=input_image, outputs=x)\n",
    "\n",
    "generator = get_generator()\n",
    "discriminator = get_discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UsZTPjDGUGu6"
   },
   "source": [
    "Now that our models are created, a sanity check must be done on the output dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "O9lmiX_bOZxO",
    "outputId": "45deb64f-b63d-4c6f-ab67-c59a6e69fa0e"
   },
   "outputs": [],
   "source": [
    "def get_noise(batch_size, nz=100):\n",
    "    return tf.random.normal([batch_size, 1, 1, nz])\n",
    "\n",
    "noise = get_noise(20)\n",
    "\n",
    "print(\"init\", noise.shape)\n",
    "fake_images = generator(noise)\n",
    "print(\"Fake images\", fake_images.shape)  # Should be (_, 64, 64, 1)\n",
    "preds = discriminator(fake_images)\n",
    "print(\"Predictions\", preds.shape)  # Should be (_, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oa0yr0aUGyCV"
   },
   "outputs": [],
   "source": [
    "generator.summary()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KKOYEtHJUdgW"
   },
   "source": [
    "## Understanding Loss Functions in DCGAN\n",
    "\n",
    "DCGAN employs two distinct loss functions to guide the training process:\n",
    "\n",
    "**1. Discriminator Loss:**\n",
    "\n",
    "* **Goal:**  The discriminator needs to accurately distinguish between real images (labeled as 'real') and generated images (labeled as 'fake'). \n",
    "* **Loss Function:** We'll use `binary_crossentropy` with the `from_logits=True` option. This combines the sigmoid activation (for probability calculation) directly within the loss calculation.\n",
    "\n",
    "**2. Generator Loss:**\n",
    "\n",
    "* **Goal:** The generator aims to deceive the discriminator into classifying its generated images as 'real'.\n",
    "* **Loss Function:**  Again, we can use `binary_crossentropy`  with `from_logits=True`. \n",
    "\n",
    "**Let's Implement These Losses:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ikqmWFOOZxX"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "def discriminator_loss(preds_real, preds_fake):\n",
    "    loss_real = binary_crossentropy(tf.ones_like(preds_real), preds_real, from_logits=True)\n",
    "    loss_fake = binary_crossentropy(tf.zeros_like(preds_fake), preds_fake, from_logits=True)\n",
    "    return loss_real + loss_fake\n",
    "\n",
    "def generator_loss(preds_fake):\n",
    "    return binary_crossentropy(tf.ones_like(preds_fake), preds_fake, from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dNos30JRYKAb"
   },
   "source": [
    "We create two optimizers, one for the discriminator and one for the generator. Remember that Adam maintains internal state for these parameters in addition to updating them. This internal state consists of \"m\" and \"v\" vectors, which are updated on each iteration. For this reason, we need to create two optimizers, one for the generator and one for the discriminator, so that we can update them separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DZQBLUTVYJSf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "discriminator_optimizer = Adam()\n",
    "generator_optimizer = Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6YobxKNcYX5p"
   },
   "source": [
    "We define our train step for a single batch. Because we are using a fairly complex architecture, we can't rely on tensorflow to automatically `fit` our model. We need to define our training loop. This method uses the `@tf.function` decorator to convert the Python function into a TensorFlow graph function. This will speed up the training process.\n",
    "\n",
    "We also use `tf.GradientTape` to record the operations for automatic differentiation. This tells TensorFlow to record the operations in the forward pass and then compute the gradients in the backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HzGiUcZh09E9"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    \"\"\"Performs a single training step for the DCGAN.\n",
    "\n",
    "    Args:\n",
    "        images: A batch of real images.\n",
    "\n",
    "    Returns:\n",
    "        disc_loss: The discriminator's loss for this step.\n",
    "        gen_loss: The generator's loss for this step.\n",
    "    \"\"\"\n",
    "    batch_size = images.shape[0]\n",
    "    noise = get_noise(batch_size)\n",
    "\n",
    "    # Train the discriminator\n",
    "    with tf.GradientTape() as disc_tape:\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generator(noise, training=True), training=True)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    # Train the generator\n",
    "    with tf.GradientTape() as gen_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "\n",
    "    return disc_loss, gen_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2wafgOpVYsx6"
   },
   "source": [
    "## Initiating DCGAN Training\n",
    "\n",
    "Now it's time to train your DCGAN! Here's what to keep in mind:\n",
    "\n",
    "* **Monitoring Losses:**  Track both discriminator and generator losses during training.  Ideally, you want to see a balance; if one loss consistently becomes too low while the other rises sharply, it indicates an imbalance in the adversarial training dynamic.\n",
    "\n",
    "* **Visualizing Progress:**  Periodically generate images using your generator. You should see realistic-looking digits emerge fairly quickly (within a few epochs). Expect finer details and overall quality to improve as training continues.\n",
    "\n",
    "**Important Note:** Reaching a perfect convergence where losses stabilize around specific values  might be less common in GAN training compared to some other deep learning tasks. The focus is often on the quality of generated samples and  achieving balance in the adversarial training process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Iva_8cuROZxv",
    "outputId": "29cc304f-c306-4fe8-83f9-4498d7799f4d"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Mean\n",
    "from IPython.display import display as jupy_display\n",
    "\n",
    "epochs = 10\n",
    "fixed_noise = get_noise(20)\n",
    "\n",
    "print(\"Initial Generated Images (using base noise):\")\n",
    "fake_images = generator(fixed_noise, training=False).numpy()\n",
    "jupy_display(display_images(fake_images))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"====== Epoch {:2d} ======\".format(epoch))\n",
    "\n",
    "    epoch_loss_d = Mean()\n",
    "    epoch_loss_g = Mean()\n",
    "\n",
    "    # Progress Indicator\n",
    "    batch_count = tf.data.experimental.cardinality(data_generator).numpy()\n",
    "    print(f\"Number of batches per epoch: {batch_count}\")\n",
    "\n",
    "    for step, real_images in enumerate(data_generator):\n",
    "        loss_d, loss_g = train_step(real_images)\n",
    "        epoch_loss_d(loss_d)\n",
    "        epoch_loss_g(loss_g)\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print(f\"--> \", end=\"\")\n",
    "\n",
    "    print(\"\\nEpoch Summary:\")\n",
    "    print(f\"  Discriminator Loss: {epoch_loss_d.result():.4f}\")\n",
    "    print(f\"  Generator Loss:     {epoch_loss_g.result():.4f}\")\n",
    "\n",
    "    #  Track Generated Images with the Same Noise \n",
    "    fake_images = generator(fixed_noise, training=False).numpy()\n",
    "    jupy_display(display_images(fake_images))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Display Final Generated Images\n",
    "\n",
    "print(\"Final Generated Images (using base noise):\")\n",
    "fake_images = generator(fixed_noise, training=False).numpy()\n",
    "jupy_display(display_images(fake_images))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wrapping Up: Your DCGAN Journey\n",
    "\n",
    "Congratulations on training your DCGAN! You've grasped the fundamentals of how GANs can generate realistic images. \n",
    "\n",
    "###  Explore and Experiment\n",
    "\n",
    "If you'd like to take your DCGAN further, here are some potential projects to try:\n",
    "\n",
    "* **Play with Noise:**  See how different shapes and distributions of your input noise influence the images your generator creates. Can you generate patterns or textures instead of realistic digits?\n",
    "\n",
    "* **Tweak the Architecture:**  Try adding or removing a convolutional layer in your generator or discriminator. Observe how this affects the quality and detail of the generated images.\n",
    "\n",
    "* **Introduce Color:**  Adapt your DCGAN to generate color images (RGB)  instead of grayscale. You'll need to adjust the output channels of your generator.\n",
    "\n",
    "* **Visualize the Training:**  Plot the discriminator and generator losses over time using a tool like Matplotlib or TensorBoard.  This can help you diagnose training issues.\n",
    "\n",
    "**Remember,  learning about GANs often involves  experimentation and seeing what works best. Have fun exploring!**\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Deep Convolutional GAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
